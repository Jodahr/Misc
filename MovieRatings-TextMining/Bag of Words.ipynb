{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis of Movie Reviews - Simple Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "from dask.multiprocessing import get\n",
    "import utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25000 entries, 0 to 24999\n",
      "Data columns (total 3 columns):\n",
      "id           25000 non-null object\n",
      "sentiment    25000 non-null int64\n",
      "review       25000 non-null object\n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 586.0+ KB\n",
      "       id  sentiment                                             review\n",
      "0  5814_8          1  With all this stuff going down at the moment w...\n",
      "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
      "2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
      "3  3630_4          0  It must be assumed that those who praised this...\n",
      "4  9495_8          1  Superbly trashy and wondrously unpretentious 8...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25000.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.50001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         sentiment\n",
       "count  25000.00000\n",
       "mean       0.50000\n",
       "std        0.50001\n",
       "min        0.00000\n",
       "25%        0.00000\n",
       "50%        0.50000\n",
       "75%        1.00000\n",
       "max        1.00000"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('labeledTrainData.tsv', sep='\\t')\n",
    "df.info()\n",
    "print(df.head())\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parallel Preprocessing with DASK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def series_preprocess(series):\n",
    "    return series.apply(utils.text_preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dask Series Structure:\n",
       "npartitions=20\n",
       "0        object\n",
       "1250        ...\n",
       "          ...  \n",
       "23750       ...\n",
       "24999       ...\n",
       "Name: review, dtype: object\n",
       "Dask Name: from_pandas, 20 tasks"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddata = dd.from_pandas(df.review, npartitions=20)\n",
    "ddata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9.64 s, sys: 259 ms, total: 9.9 s\n",
      "Wall time: 2min 55s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "res = ddata.map_partitions(series_preprocess).compute(get=get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review_preprocessed_tokenized'] = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['review_preprocessed'] = df['review_preprocessed_tokenized'].apply(lambda x: ' '.join(x) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "      <th>review_preprocessed</th>\n",
       "      <th>review_preprocessed_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5814_8</td>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "      <td>stuff go moment mj start listen music watch od...</td>\n",
       "      <td>[stuff, go, moment, mj, start, listen, music, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2381_9</td>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "      <td>classic war world timothi hine veri entertain ...</td>\n",
       "      <td>[classic, war, world, timothi, hine, veri, ent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7759_3</td>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "      <td>film start manag nichola bell give welcom inve...</td>\n",
       "      <td>[film, start, manag, nichola, bell, give, welc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3630_4</td>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "      <td>must assum prais film greatest film opera ever...</td>\n",
       "      <td>[must, assum, prais, film, greatest, film, ope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9495_8</td>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "      <td>superbl trashi wondrous unpretenti 80 exploit ...</td>\n",
       "      <td>[superbl, trashi, wondrous, unpretenti, 80, ex...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  sentiment                                             review  \\\n",
       "0  5814_8          1  With all this stuff going down at the moment w...   \n",
       "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...   \n",
       "2  7759_3          0  The film starts with a manager (Nicholas Bell)...   \n",
       "3  3630_4          0  It must be assumed that those who praised this...   \n",
       "4  9495_8          1  Superbly trashy and wondrously unpretentious 8...   \n",
       "\n",
       "                                 review_preprocessed  \\\n",
       "0  stuff go moment mj start listen music watch od...   \n",
       "1  classic war world timothi hine veri entertain ...   \n",
       "2  film start manag nichola bell give welcom inve...   \n",
       "3  must assum prais film greatest film opera ever...   \n",
       "4  superbl trashi wondrous unpretenti 80 exploit ...   \n",
       "\n",
       "                       review_preprocessed_tokenized  \n",
       "0  [stuff, go, moment, mj, start, listen, music, ...  \n",
       "1  [classic, war, world, timothi, hine, veri, ent...  \n",
       "2  [film, start, manag, nichola, bell, give, welc...  \n",
       "3  [must, assum, prais, film, greatest, film, ope...  \n",
       "4  [superbl, trashi, wondrous, unpretenti, 80, ex...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_pickle('reviews.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle('reviews.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "      <th>review_preprocessed</th>\n",
       "      <th>review_preprocessed_tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5814_8</td>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "      <td>stuff go moment mj start listen music watch od...</td>\n",
       "      <td>[stuff, go, moment, mj, start, listen, music, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2381_9</td>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "      <td>classic war world timothi hine veri entertain ...</td>\n",
       "      <td>[classic, war, world, timothi, hine, veri, ent...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7759_3</td>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "      <td>film start manag nichola bell give welcom inve...</td>\n",
       "      <td>[film, start, manag, nichola, bell, give, welc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3630_4</td>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "      <td>must assum prais film greatest film opera ever...</td>\n",
       "      <td>[must, assum, prais, film, greatest, film, ope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9495_8</td>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "      <td>superbl trashi wondrous unpretenti 80 exploit ...</td>\n",
       "      <td>[superbl, trashi, wondrous, unpretenti, 80, ex...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  sentiment                                             review  \\\n",
       "0  5814_8          1  With all this stuff going down at the moment w...   \n",
       "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...   \n",
       "2  7759_3          0  The film starts with a manager (Nicholas Bell)...   \n",
       "3  3630_4          0  It must be assumed that those who praised this...   \n",
       "4  9495_8          1  Superbly trashy and wondrously unpretentious 8...   \n",
       "\n",
       "                                 review_preprocessed  \\\n",
       "0  stuff go moment mj start listen music watch od...   \n",
       "1  classic war world timothi hine veri entertain ...   \n",
       "2  film start manag nichola bell give welcom inve...   \n",
       "3  must assum prais film greatest film opera ever...   \n",
       "4  superbl trashi wondrous unpretenti 80 exploit ...   \n",
       "\n",
       "                       review_preprocessed_tokenized  \n",
       "0  [stuff, go, moment, mj, start, listen, music, ...  \n",
       "1  [classic, war, world, timothi, hine, veri, ent...  \n",
       "2  [film, start, manag, nichola, bell, give, welc...  \n",
       "3  [must, assum, prais, film, greatest, film, ope...  \n",
       "4  [superbl, trashi, wondrous, unpretenti, 80, ex...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer, CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df['review_preprocessed'], df['sentiment'], test_size=0.2, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_matrix = count_vectorizer.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20000, 46690)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_matrix.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.sparse import csr_matrix, csc_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0],\n",
       "        [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csr_matrix.todense(sparse_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46690"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count_vectorizer.vocabulary_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_split = X_train.apply(lambda x: x.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "words, counts = utils.wordcount_corpus(X_train_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>word</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>27726</th>\n",
       "      <td>41381</td>\n",
       "      <td>movi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14840</th>\n",
       "      <td>38650</td>\n",
       "      <td>film</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29664</th>\n",
       "      <td>22221</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24132</th>\n",
       "      <td>18247</td>\n",
       "      <td>like</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41600</th>\n",
       "      <td>12817</td>\n",
       "      <td>time</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       count  word\n",
       "27726  41381  movi\n",
       "14840  38650  film\n",
       "29664  22221   one\n",
       "24132  18247  like\n",
       "41600  12817  time"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_counts_df = pd.DataFrame({'word': words, 'count': counts}).sort_values(by='count', ascending=False)\n",
    "word_counts_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_pipe = Pipeline([\n",
    "    ('count_vectorizer', CountVectorizer()),\n",
    "    ('classifier', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('count_vectorizer', CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
       "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
       "        tokenizer=None, vocabulary=None)), ('classifier', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8542"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple_pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF (Term Frequency - Inverse Document Frequency)\n",
    "\n",
    "Words appearing very often in the whole corpus do not carry a lot of information, e.g. the word Movie or Film in our corpus.\n",
    "\n",
    "- numerical statistic\n",
    "- should reflect how important a word in a document is by considering the whole corpus\n",
    "- can be seen as a weighting factor\n",
    "- increases by increasing wordcount of the word in the document\n",
    "- offset by frequency of the word in the whole corpus\n",
    "- most used term-weighting scheme\n",
    "\n",
    "\n",
    "Product of two statistics:\n",
    "\\begin{align}\n",
    "tf\\text{-}idf(t,d) = tf(t,d) \\times idf(t)\n",
    "\\end{align}\n",
    "\n",
    "where tf(t,d) is the frequency of the term/word t in document d and\n",
    "\n",
    "\\begin{align}\n",
    "idf(t) = \\ln\\left(\\frac{n_d}{df(d,t)}\\right)\n",
    "\\end{align}\n",
    "\n",
    "is the logarithmically scaled inverse fraction of the documents that contain the word, obtained by dividing the total number of documents $n_d$ by the number of documents containing the term $df$, and then taking the logarithm of that quotient. Most often it is smoothed by adding a one in the denominator and add a final one, leading to:\n",
    "\n",
    "\\begin{align}\n",
    "idf(t) = \\ln\\left(\\frac{n_d}{df(d,t)}\\right) + 1\n",
    "\\end{align}\n",
    "\n",
    "Finally, the resulting vector of a weighted wordcount vector in normalized using L2 norm (normalized to length 1).\n",
    "\n",
    "For more information see: http://scikit-learn.org/stable/modules/feature_extraction.html#text-feature-extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The brown brown brown fox',\n",
       " 'The lazy dog',\n",
       " 'The fox is brown',\n",
       " 'black is a color']"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [\n",
    "    \"The brown brown brown fox\",\n",
    "    \"The lazy dog\",\n",
    "    \"The fox is brown\",\n",
    "    \"black is a color\",\n",
    "]\n",
    "\n",
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_matrix = count_vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 3, 0, 0, 1, 0, 0, 1],\n",
       "        [0, 0, 0, 1, 0, 0, 1, 1],\n",
       "        [0, 1, 0, 0, 1, 1, 0, 1],\n",
       "        [1, 0, 1, 0, 0, 1, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_counts = csr_matrix.todense(sparse_matrix)\n",
    "corpus_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['black', 'brown', 'color', 'dog', 'fox', 'is', 'lazy', 'the']"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(smooth_idf=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "sparse_matrix = tfidf_vectorizer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0.        , 0.92238296, 0.        , 0.        , 0.30746099,\n",
       "         0.        , 0.        , 0.23383201],\n",
       "        [0.        , 0.        , 0.        , 0.66064766, 0.        ,\n",
       "         0.        , 0.66064766, 0.3564959 ],\n",
       "        [0.        , 0.52863461, 0.        , 0.        , 0.52863461,\n",
       "         0.52863461, 0.        , 0.40204024],\n",
       "        [0.63202178, 0.        , 0.63202178, 0.        , 0.        ,\n",
       "         0.44843834, 0.        , 0.        ]])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus_weighted_counts = csr_matrix.todense(sparse_matrix)\n",
    "corpus_weighted_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['black', 'brown', 'color', 'dog', 'fox', 'is', 'lazy', 'the']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.079441541679836"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# brown\n",
    "import math\n",
    "tf = 3\n",
    "nd = 4\n",
    "df = 2 \n",
    "\n",
    "idf = math.log(nd/df) + 1\n",
    "tfidf_brown = tf * idf\n",
    "tfidf_brown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2876820724517808"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The\n",
    "import math\n",
    "tf = 1\n",
    "nd = 4\n",
    "df = 3 \n",
    "\n",
    "idf = math.log(nd/df) + 1\n",
    "tfidf_the = tf * idf\n",
    "tfidf_the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6931471805599454"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fox\n",
    "import math\n",
    "tf = 1\n",
    "nd = 4\n",
    "df = 2 \n",
    "\n",
    "idf = math.log(nd/df) + 1\n",
    "tfidf_fox = tf * idf\n",
    "tfidf_fox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 5.07944154, 0.        , 0.        , 0.        ,\n",
       "       1.69314718, 0.        , 0.        , 1.28768207])"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec = np.array([0,tfidf_brown,0,0,0,tfidf_fox, 0, 0, tfidf_the])\n",
    "vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.92238296, 0.        , 0.        , 0.        ,\n",
       "       0.30746099, 0.        , 0.        , 0.23383201])"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy.linalg import norm\n",
    "norm(vec)\n",
    "vec/np.sqrt(np.dot(vec,vec))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_pipe = Pipeline([\n",
    "    ('tfidf_vectorizer', TfidfVectorizer()),\n",
    "    ('classifier', MultinomialNB())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('tfidf_vectorizer', TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "        lowercase=True, max_df=1.0, max_features=None, min_df=1,\n",
       "        ngram_range=(1, 1), norm='l2', preprocessor=None, smooth_...      vocabulary=None)), ('classifier', MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8564"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_pipe.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_scores = cross_val_score(simple_pipe, X_train, y_train, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_scores = cross_val_score(tfidf_pipe, X_train, y_train, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8554493931248481, 0.00875385021170826)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(simple_scores), np.std(simple_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8610494185123546, 0.009206620423056443)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(tfidf_scores), np.std(tfidf_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.84      0.87      0.86      2481\n",
      "          1       0.87      0.84      0.85      2519\n",
      "\n",
      "avg / total       0.85      0.85      0.85      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, simple_pipe.predict(X_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.85      0.86      0.86      2481\n",
      "          1       0.86      0.85      0.86      2519\n",
      "\n",
      "avg / total       0.86      0.86      0.86      5000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, tfidf_pipe.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only slightly better since we have already removed lots of stop words :). However, the dimension of the feature space is of the size of the vocabulary and hence very large. There is another way to get a representation in a smaller vector space. This method is called word2vec."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
